\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\AC@reset@newl@bel
\citation{PhysRevLett.116.061102,PhysRevLett.119.161101}
\citation{2018arXiv181112907T}
\citation{2018LRR....21....3A}
\providecommand \oddpage@label [2]{}
\newlabel{firstpage}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{kruckow2018progenitors}
\citation{2017ApJ...851L..25F}
\citation{2018arXiv181112907T}
\citation{2019ApJ...872..105S}
\citation{2018arXiv180700011F}
\citation{1993A&A...271..149K}
\citation{1996ApJ...465..338P}
\citation{1996ApJ...471..352K}
\citation{1998ApJ...493..351K,2000ApJ...541..319K}
\citation{andrews2017dart_board}
\citation{2017IAUS..325...46B}
\citation{2018arXiv180608365T}
\citation{jones1977blindfold}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{2}{section.2}\protected@file@percent }
\newlabel{sec:sampling-methods}{{2}{2}{Method}{section.2}{}}
\citation{kahn1951estimation,10.2307/166789}
\citation{torrie1977nonphysical,doi:10.1080/00401706.1995.10484303,ortiz2000adaptive,pennanen2006adaptive,cappe2004population,cornuet2012adaptive}
\citation{2007arXiv0710.4242C}
\citation{cornuet2012adaptive}
\citation{1990ApJS...74..551A,2017ApJS..230...15M,2018A&A...619A..77K}
\citation{osti_4423221,doi:10.1080/01621459.1949.10483310}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Definition of concepts and symbols}{3}{subsection.2.1}\protected@file@percent }
\newlabel{sec:BPS}{{2.1}{3}{Definition of concepts and symbols}{subsection.2.1}{}}
\newlabel{eq:prior-3d}{{1}{3}{Definition of concepts and symbols}{equation.1}{}}
\newlabel{eq:output-input}{{2}{3}{Definition of concepts and symbols}{equation.2}{}}
\newlabel{eq:unityfunction}{{3}{3}{Definition of concepts and symbols}{equation.3}{}}
\citation{10.2307/166789}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Illustration of the \textsc  {STROOPWAFEL}\ algorithm. In the algorithm, (I) we first draw random binaries from the birth distribution $\pi $ until a small population of events of interest (hits) is found. (II) We construct Gaussian distributions around each of the previously found successful events. We create an adapted instrumental distribution $q(\boldsymbol  {x})$ from the mixture of Gaussian distributions. We scale the width of each Gaussian with the local sampling density. (III) We draw the remaining samples from this adapted distribution which focuses around the target population. The top panels show a random draw of samples from the corresponding distribution in the lower panel. The samples are assigned a random scatter in the y-direction for the visualization.}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:aIS_scheme}{{1}{4}{Illustration of the \AISs \ algorithm. In the algorithm, (I) we first draw random binaries from the birth distribution $\pi $ until a small population of events of interest (hits) is found. (II) We construct Gaussian distributions around each of the previously found successful events. We create an adapted instrumental distribution $q(\boldsymbol {x})$ from the mixture of Gaussian distributions. We scale the width of each Gaussian with the local sampling density. (III) We draw the remaining samples from this adapted distribution which focuses around the target population. The top panels show a random draw of samples from the corresponding distribution in the lower panel. The samples are assigned a random scatter in the y-direction for the visualization}{figure.1}{}}
\newlabel{eq:unbiased}{{6}{4}{Definition of concepts and symbols}{equation.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adaptive sampling algorithm to increase efficiency of simulation}{4}{subsection.2.2}\protected@file@percent }
\newlabel{subsec:AISalgorithm}{{2.2}{4}{Adaptive sampling algorithm to increase efficiency of simulation}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}The instrumental distribution}{4}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{subsec:instrumental-distribution}{{2.2.1}{4}{The instrumental distribution}{subsubsection.2.2.1}{}}
\newlabel{eq:weights}{{7}{4}{The instrumental distribution}{equation.7}{}}
\newlabel{eq:instrumental}{{8}{4}{The instrumental distribution}{equation.8}{}}
\citation{robert2013monte}
\citation{Veach:1995:OCS:218380.218498}
\citation{doi:10.1080/00401706.1995.10484303}
\citation{doi:10.1080/01621459.2000.10473909}
\citation{cornuet2012adaptive}
\citation{2014arXiv1411.3954H}
\citation{Veach:1995:OCS:218380.218498}
\citation{cornuet2012adaptive}
\newlabel{eq:instrumental}{{9}{5}{The instrumental distribution}{equation.9}{}}
\newlabel{eq:covariance-matrix}{{10}{5}{The instrumental distribution}{equation.10}{}}
\newlabel{eq:sigmajk}{{11}{5}{The instrumental distribution}{equation.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Combining samples from the exploratory phase and refinement phase}{5}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{subsec:CombiningSamples}{{2.2.2}{5}{Combining samples from the exploratory phase and refinement phase}{subsubsection.2.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of the parameters that are used throughout this paper. Hits refer to binaries of the chosen target population.}}{5}{table.1}\protected@file@percent }
\newlabel{tab:variables}{{1}{5}{Summary of the parameters that are used throughout this paper. Hits refer to binaries of the chosen target population}{table.1}{}}
\newlabel{eq:CombinedDistribution}{{12}{5}{Combining samples from the exploratory phase and refinement phase}{equation.12}{}}
\newlabel{eq:weightsMixture}{{13}{5}{Combining samples from the exploratory phase and refinement phase}{equation.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Calculating statistical estimates using the adaptive distribution}{5}{subsubsection.2.2.3}\protected@file@percent }
\newlabel{subsec:AISstatistic}{{2.2.3}{5}{Calculating statistical estimates using the adaptive distribution}{subsubsection.2.2.3}{}}
\citation{doi:10.1080/00401706.1995.10484303,liu2008monte}
\newlabel{eq:ISestimator}{{14}{6}{Calculating statistical estimates using the adaptive distribution}{equation.14}{}}
\newlabel{eq:variance}{{15}{6}{Calculating statistical estimates using the adaptive distribution}{equation.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}The duration of the exploratory phase}{6}{subsubsection.2.2.4}\protected@file@percent }
\newlabel{subsec:durationExploratory}{{2.2.4}{6}{The duration of the exploratory phase}{subsubsection.2.2.4}{}}
\newlabel{eq:EstimateFexpl}{{16}{6}{The duration of the exploratory phase}{equation.16}{}}
\newlabel{eq:VarFprior}{{17}{6}{The duration of the exploratory phase}{equation.17}{}}
\newlabel{eq:FexplSolutionComplicated}{{18}{6}{The duration of the exploratory phase}{equation.18}{}}
\newlabel{eq:FexplSolutionSimple}{{19}{6}{The duration of the exploratory phase}{equation.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Determining the free parameter $\kappa $ from tests with a toy model }{7}{subsubsection.2.2.5}\protected@file@percent }
\newlabel{subsec:kappaAndToymodel}{{2.2.5}{7}{Determining the free parameter $\kappa $ from tests with a toy model}{subsubsection.2.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Summary of \textsc  {STROOPWAFEL}\ algorithm}{7}{subsubsection.2.2.6}\protected@file@percent }
\newlabel{subsubsec:algorithmflow}{{2.2.6}{7}{Summary of \AISs \ algorithm}{subsubsection.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Characteristic behaviour}{7}{subsection.2.3}\protected@file@percent }
\newlabel{subsec:characteristics}{{2.3}{7}{Characteristic behaviour}{subsection.2.3}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textsc  {STROOPWAFEL}\ algorithm}}{7}{algocf.1}\protected@file@percent }
\newlabel{alg:expl}{{1}{7}{Summary of \AISs \ algorithm}{algocf.1}{}}
\citation{stevenson2017formation,2018MNRAS.477.4685B,2018MNRAS.481.4009V}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {Top panel:} the fraction of total samples that should be spent on the exploratory phase versus the fractional rate, $\mathcal  {R}_{\text  {T}}$, of the target population in a simulation. Different curves show the effect of varying the total number of samples $N$ in the simulation. \textbf  {Bottom panel:} expected sampling uncertainty on the predicted event rate versus the fractional rate, for two different choices of $N$. The dashed lines show the expected uncertainty from "traditional" Monte Carlo sampling (i.e., $\sqrt  {{\mathbb  {V}_{\pi }[\mathcal  {R}_{\text  {T}}]}}/\mathcal  {R}_{\text  {T}}$ ). The solid lines show the minimum possible statistical uncertainty from \textsc  {STROOPWAFEL}{} sampling, i.e., if the efficiency in the refinement phase is 1. In practice the statistical rate uncertainty when using \textsc  {STROOPWAFEL}{} will lie in the area shaded in grey. \textbf  {All panels:} coloured vertical bars indicate the fractional rate of the target populations, and star symbols show the corresponding values of these parameters, for the six simulations with $N= 10^6$ described in Section \ref  {sec:Results}.}}{8}{figure.2}\protected@file@percent }
\newlabel{fig:fractionPrior}{{2}{8}{\textbf {Top panel:} the fraction of total samples that should be spent on the exploratory phase versus the fractional rate, $\rate _{\text {T}}$, of the target population in a simulation. Different curves show the effect of varying the total number of samples $N$ in the simulation. \textbf {Bottom panel:} expected sampling uncertainty on the predicted event rate versus the fractional rate, for two different choices of $N$. The dashed lines show the expected uncertainty from "traditional" Monte Carlo sampling (i.e., $\sqrt {{\mathbb {V}_{\pi }[\rate _{\text {T}}]}}/\rate _{\text {T}}$ ). The solid lines show the minimum possible statistical uncertainty from \AISs {} sampling, i.e., if the efficiency in the refinement phase is 1. In practice the statistical rate uncertainty when using \AISs {} will lie in the area shaded in grey. \textbf {All panels:} coloured vertical bars indicate the fractional rate of the target populations, and star symbols show the corresponding values of these parameters, for the six simulations with $N= 10^6$ described in Section \ref {sec:Results}}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The ratio of the number of target binaries found with \textsc  {STROOPWAFEL}{} to the number found when Monte Carlo sampling from the birth distribution -- i.e., the multiplicative gain achieved by \textsc  {STROOPWAFEL}{} -- as a function of rareness of the target population. The red curves give this gain for two different efficiencies in the refinement phase, as labelled. The gain is shown for simulations with a total of $N=10^6$ samples. Coloured vertical bars and star symbols present the values for the six simulations described in Section \ref  {sec:Results}, as given in the last column of Table\nobreakspace  {}\ref  {tab:comparison2}. }}{8}{figure.3}\protected@file@percent }
\newlabel{fig:gain-for-imperfect-efficiency}{{3}{8}{The ratio of the number of target binaries found with \AISs {} to the number found when Monte Carlo sampling from the birth distribution -- i.e., the multiplicative gain achieved by \AISs {} -- as a function of rareness of the target population. The red curves give this gain for two different efficiencies in the refinement phase, as labelled. The gain is shown for simulations with a total of $N=10^6$ samples. Coloured vertical bars and star symbols present the values for the six simulations described in Section \ref {sec:Results}, as given in the last column of Table~\ref {tab:comparison2}}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}{section.3}\protected@file@percent }
\newlabel{sec:Results}{{3}{8}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}On the gain of generating binaries of the target distribution}{9}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:VerificationCOMPASefficiency}{{3.1}{9}{On the gain of generating binaries of the target distribution}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Speeding up simulations}{9}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:VerificationCOMPASspeedUp}{{3.2}{9}{Speeding up simulations}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The number of simulated binaries $N_{\mathrm  {T}}$ falling into the target population as a function of the total number of binaries $N_{\text  {binaries}}$ sampled for the traditional sampling method (gray dashed line) and the sampling method presented in this study (solid coloured line). The four panels show the simulations for each of the four target sub-populations. In each panel the duration of the exploratory phase is shown with a hashed gray area. In the background the standard Poisson fractional uncertainties of $0.3, 1$ and $3\%$ are shown with dashed lines. }}{10}{figure.4}\protected@file@percent }
\newlabel{fig:NbinariesVsNHits}{{4}{10}{The number of simulated binaries $N_{\mathrm {T}}$ falling into the target population as a function of the total number of binaries $N_{\text {binaries}}$ sampled for the traditional sampling method (gray dashed line) and the sampling method presented in this study (solid coloured line). The four panels show the simulations for each of the four target sub-populations. In each panel the duration of the exploratory phase is shown with a hashed gray area. In the background the standard Poisson fractional uncertainties of $0.3, 1$ and $3\%$ are shown with dashed lines}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of the results from six target populations that are modelled in this paper to demonstrate our \textsc  {STROOPWAFEL}{} algorithm. We list the fraction of samples spent in the exploratory phase, $f_{\rm  {expl}}$, and the efficiency of finding `hits' in the exploratory and refinement phases. The gain in refinement is the ratio between the efficiency of finding samples of the target population during the refinement phase of \textsc  {STROOPWAFEL}{} and traditional sampling (where the efficiency of traditional sampling is equal to the efficiency of the \textsc  {STROOPWAFEL}{} exploratory phase). $N_{\text  {T,traditional}}$ and $ N_{\text  {T,\textsc  {STROOPWAFEL}{}}}$ represent the total number of systems of interest that are found by the end of the simulation (using a total of $10^6$ samples). The last column is the overall gain that we found when using \textsc  {STROOPWAFEL}{} compared to traditional Monte Carlo sampling from the birth distributions, which is defined by the ratio $ N_{\text  {T,\textsc  {STROOPWAFEL}{}}}$ / $N_{\text  {T,traditional}}$. \href  {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}{{\FAtwo  \char 8\relax }}}}}{10}{table.2}\protected@file@percent }
\newlabel{tab:comparison2}{{2}{10}{Summary of the results from six target populations that are modelled in this paper to demonstrate our \AISs {} algorithm. We list the fraction of samples spent in the exploratory phase, $f_{\rm {expl}}$, and the efficiency of finding `hits' in the exploratory and refinement phases. The gain in refinement is the ratio between the efficiency of finding samples of the target population during the refinement phase of \AISs {} and traditional sampling (where the efficiency of traditional sampling is equal to the efficiency of the \AISs {} exploratory phase). $N_{\text {T,traditional}}$ and $ N_{\text {T,\AISs {}}}$ represent the total number of systems of interest that are found by the end of the simulation (using a total of $10^6$ samples). The last column is the overall gain that we found when using \AISs {} compared to traditional Monte Carlo sampling from the birth distributions, which is defined by the ratio $ N_{\text {T,\AISs {}}}$ / $N_{\text {T,traditional}}$. \href {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}\faBook }}{table.2}{}}
\citation{stevenson2017formation,2018MNRAS.481.4009V}
\citation{2018arXiv181112907T}
\citation{2019arXiv190210331Z}
\citation{2018MNRAS.477.4685B}
\citation{2015MNRAS.451.4086S,2016Natur.534..512B,2019arXiv190608136N}
\citation{10.1093/mnras/stw379,2016MNRAS.460.3545D,2016A&A...588A..50M}
\citation{2018arXiv180605820M,2018arXiv180909130M}
\citation{2018arXiv181112907T,2019arXiv190210331Z}
\citation{2012ApJ...749...91F}
\citation{2018MNRAS.481.4009V}
\citation{2018arXiv181112907T}
\citation{2019arXiv190210331Z}
\citation{2018arXiv181112907T}
\citation{2019arXiv190210331Z}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sampling uncertainty estimate from each simulation of the target population. Gray bars show the uncertainty from traditional sampling methods whereas the coloured bars show the uncertainty from our sampling method \textsc  {STROOPWAFEL}. All simulations use a total of $10^6$ samples. The number shown on top of the traditional bar shows the factor in decrease in uncertainty from \textsc  {STROOPWAFEL}{} compared to traditional sampling for that simulation. \href  {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}{{\FAtwo  \char 8\relax }}}}}{11}{figure.5}\protected@file@percent }
\newlabel{fig:RatesUncertainties}{{5}{11}{Sampling uncertainty estimate from each simulation of the target population. Gray bars show the uncertainty from traditional sampling methods whereas the coloured bars show the uncertainty from our sampling method \AISs . All simulations use a total of $10^6$ samples. The number shown on top of the traditional bar shows the factor in decrease in uncertainty from \AISs {} compared to traditional sampling for that simulation. \href {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}\faBook }}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Mapping the parameter space with higher resolution}{11}{subsection.3.3}\protected@file@percent }
\newlabel{subsec:BHNSimprovement_moreHits}{{3.3}{11}{Mapping the parameter space with higher resolution}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Smaller variances in distribution functions}{11}{subsection.3.4}\protected@file@percent }
\newlabel{subsec:showcaseBHNS-smallerVariance}{{3.4}{11}{Smaller variances in distribution functions}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Contour plots of the locations in $\qopname  \relax o{log}\ m_{\rm  {1,i}}$ and $\qopname  \relax o{log}\tmspace  +\thinmuskip {.1667em} a_{\rm  {i}}$ space of the hits $\boldsymbol  {{x_{\rm  {T}}}}$ (i.e., binaries of the target population) found in each simulation when using traditional birth distribution Monte Carlo sampling (left panels) and the sampling method \textsc  {STROOPWAFEL}\ developed in this study (right panels). Contours represent a constant density of binaries of the target population found per unit area in $\qopname  \relax o{log}\ m_{\rm  {1,i}}$ -- $\qopname  \relax o{log}\tmspace  +\thinmuskip {.1667em} a_{\rm  {i}}$ space. The colour gradient indicates the number of samples per area $\Delta S$, the size of which is shown with a black rectangle. If the density is below the level of our lowest contour we plot the individual points. The four different panels from top to bottom represent the first four target populations shown in Table \ref  {tab:comparison2}. The total number of hits $N_{\text  {T}}$ found in each simulation is quoted in parentheses. The metallicity assumed in all simulations is $Z = 0.001$. }}{12}{figure.6}\protected@file@percent }
\newlabel{fig:ContourPlotInitial}{{6}{12}{Contour plots of the locations in $\log \ m_{\rm {1,i}}$ and $\log \, a_{\rm {i}}$ space of the hits $\boldsymbol {{x_{\rm {T}}}}$ (i.e., binaries of the target population) found in each simulation when using traditional birth distribution Monte Carlo sampling (left panels) and the sampling method \AISs \ developed in this study (right panels). Contours represent a constant density of binaries of the target population found per unit area in $\log \ m_{\rm {1,i}}$ -- $\log \, a_{\rm {i}}$ space. The colour gradient indicates the number of samples per area $\Delta S$, the size of which is shown with a black rectangle. If the density is below the level of our lowest contour we plot the individual points. The four different panels from top to bottom represent the first four target populations shown in Table \ref {tab:comparison2}. The total number of hits $N_{\text {T}}$ found in each simulation is quoted in parentheses. The metallicity assumed in all simulations is $Z = 0.001$}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Similar to Figure\nobreakspace  {}\ref  {fig:ContourPlotInitial} but now for the output parameters: the final compact object masses $\rm  {m_{\rm  {1,f}}}$ and $\rm  {m_{\rm  {2,f}}}$ of the DCO. We overplot the gravitational-wave observations from O1 and O2 from \citet  {2018arXiv181112907T} in black and from \citet  {2019arXiv190210331Z} in red. Error bars indicate 90$\%$ credible regions around the median. The metallicity assumed in all simulations is $Z = 0.001$; selection effects of gravitational-wave detectors are not accounted for.}}{13}{figure.7}\protected@file@percent }
\newlabel{fig:ContourPlotFinal}{{7}{13}{Similar to Figure~\ref {fig:ContourPlotInitial} but now for the output parameters: the final compact object masses $\rm {m_{\rm {1,f}}}$ and $\rm {m_{\rm {2,f}}}$ of the DCO. We overplot the gravitational-wave observations from O1 and O2 from \citet {2018arXiv181112907T} in black and from \citet {2019arXiv190210331Z} in red. Error bars indicate 90$\%$ credible regions around the median. The metallicity assumed in all simulations is $Z = 0.001$; selection effects of gravitational-wave detectors are not accounted for}{figure.7}{}}
\citation{2017ApJ...851L..25F}
\citation{2017ApJ...851L..25F}
\citation{2017ApJ...851L..25F}
\citation{10.2307/1268522,eglajs1977new,iman1980latin,iman1981approach}
\citation{euler1782recherches}
\citation{cornuet2012adaptive}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Recovering tails of distribution functions}{14}{subsection.3.5}\protected@file@percent }
\newlabel{subsec:results-tails-of-distributions}{{3.5}{14}{Recovering tails of distribution functions}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Handling bifurcations and stochasticity}{14}{subsection.3.6}\protected@file@percent }
\newlabel{subsec:handling-bifurcations}{{3.6}{14}{Handling bifurcations and stochasticity}{subsection.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{14}{section.4}\protected@file@percent }
\newlabel{sec:discussion}{{4}{14}{Discussion}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The exploratory phase}{14}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The refined sampling phase}{14}{subsection.4.2}\protected@file@percent }
\newlabel{subsec:discussion-refinedSampling}{{4.2}{14}{The refined sampling phase}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Left panel:} histograms of the number of target BH--NS binaries $N_{\rm  {T}}$ found per chirp mass bin $m_{\rm  {chirp}}$ for traditional Monte Carlo sampling (grey) and the \textsc  {STROOPWAFEL}{} sampling method presented in this study (green). The standard Monte Carlo fractional uncertainties (i.e. Poisson noise) are shown with dashed lines in the background. We mark everything below 4 events (i.e. $50\%$ uncertainty) as statistically insignificant as it is consistent with no hits within 2 standard deviations. \textbf  {Right panel:} the BH-NS chirp mass probability distribution; {\textsc  {STROOPWAFEL}{} results have been re-sampled with weights from Eq.\nobreakspace  {}(\ref  {eq:weightsMixture}).} The metallicity assumed in the simulations is $Z = 0.001$. The bin width is approximately $ 0.2 M_{\odot }$ and is constant between the traditional and \textsc  {STROOPWAFEL}{} algorithm. \href  {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}{{\FAtwo  \char 8\relax }}}}}{15}{figure.8}\protected@file@percent }
\newlabel{fig:mtotHistograms}{{8}{15}{\textbf {Left panel:} histograms of the number of target BH--NS binaries $N_{\rm {T}}$ found per chirp mass bin $m_{\rm {chirp}}$ for traditional Monte Carlo sampling (grey) and the \AISs {} sampling method presented in this study (green). The standard Monte Carlo fractional uncertainties (i.e. Poisson noise) are shown with dashed lines in the background. We mark everything below 4 events (i.e. $50\%$ uncertainty) as statistically insignificant as it is consistent with no hits within 2 standard deviations. \textbf {Right panel:} the BH-NS chirp mass probability distribution; {\AISs {} results have been re-sampled with weights from Eq.~(\ref {eq:weightsMixture}).} The metallicity assumed in the simulations is $Z = 0.001$. The bin width is approximately $ 0.2 M_{\odot }$ and is constant between the traditional and \AISs {} algorithm. \href {https://doi.org/10.5281/zenodo.3387651}{\color {linkcolor}\faBook }}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Predicted distribution of the chirp mass of the merging BH--NS population using \textsc  {STROOPWAFEL}{} (green) and traditional (grey) sampling. In both cases the simulation uses $N= 10^6$ samples and the distributions are weighted by the sensitivity of gravitational-wave interferometers using \citet  {2017ApJ...851L..25F}. Shaded regions show the $1$- and $2$--$\sigma $ confidence intervals which are calculated by bootstrapping the samples 1000 times. This distribution is for a particular set of model assumptions, including a single metallicity $Z = 0.001$, and an integration over a metallicity-dependent cosmic star formation history is required for comparisons with observations. The same \texttt  {scipy} kernel density estimator smoothing with a dimensionless kernel density estimator factor of about $0.1 $ is used for traditional and \textsc  {STROOPWAFEL}{} distributions (see also Appendix \ref  {app:KDEbandwidth}).}}{15}{figure.9}\protected@file@percent }
\newlabel{fig:Mchirpkde}{{9}{15}{Predicted distribution of the chirp mass of the merging BH--NS population using \AISs {} (green) and traditional (grey) sampling. In both cases the simulation uses $N= 10^6$ samples and the distributions are weighted by the sensitivity of gravitational-wave interferometers using \citet {2017ApJ...851L..25F}. Shaded regions show the $1$- and $2$--$\sigma $ confidence intervals which are calculated by bootstrapping the samples 1000 times. This distribution is for a particular set of model assumptions, including a single metallicity $Z = 0.001$, and an integration over a metallicity-dependent cosmic star formation history is required for comparisons with observations. The same \texttt {scipy} kernel density estimator smoothing with a dimensionless kernel density estimator factor of about $0.1 $ is used for traditional and \AISs {} distributions (see also Appendix \ref {app:KDEbandwidth})}{figure.9}{}}
\citation{andrews2017dart_board}
\citation{andrews2017dart_board}
\citation{2017IAUS..325...46B,2018arXiv180608365T}
\citation{2018MNRAS.479..601D}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Adapting to uncertainty in distribution functions}{16}{subsection.4.3}\protected@file@percent }
\newlabel{subsec:discussion-adaptingUncertainty}{{4.3}{16}{Adapting to uncertainty in distribution functions}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\textsc  {STROOPWAFEL}{} in higher dimensions}{16}{subsection.4.4}\protected@file@percent }
\newlabel{subsec:DiscussionHigherDim}{{4.4}{16}{\AISs {} in higher dimensions}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Combining \textsc  {STROOPWAFEL}\ with MCMC or Gaussian process regression emulators on continuous spaces}{16}{subsection.4.5}\protected@file@percent }
\newlabel{subsec:DiscussionContinuousSpaces}{{4.5}{16}{Combining \AISs \ with MCMC or Gaussian process regression emulators on continuous spaces}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Summary and conclusions}{16}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{16}{Summary and conclusions}{section.5}{}}
\citation{stevenson2017formation,2018MNRAS.477.4685B,2018MNRAS.481.4009V}
\citation{2007CSE.....9...90H}
\citation{2011CSE....13b..22V}
\citation{2007CSE.....9c..21P,kluyver2016jupyter}
\bibstyle{mnras}
\bibdata{my_bib}
\bibcite{PhysRevLett.116.061102}{{1}{2016}{{Abbott et~al.}}{{Abbott et~al.,}}}
\bibcite{PhysRevLett.119.161101}{{2}{2017}{{Abbott et~al.}}{{Abbott et~al.,}}}
\bibcite{2018LRR....21....3A}{{3}{2018}{{Abbott et~al.}}{{Abbott et~al.}}}
\bibcite{1983ARA&A..21..343A}{{4}{1983}{{{Abt}}}{{{Abt}}}}
\bibcite{1990ApJS...74..551A}{{5}{1990}{{{Abt} et~al.}}{{{Abt}, {Gomez} \& {Levy}}}}
\bibcite{andrews2017dart_board}{{6}{2018}{{{Andrews} et~al.}}{{{Andrews}, {Zezas} \& {Fragos}}}}
\bibcite{2017IAUS..325...46B}{{7}{2017}{{{Barrett} et~al.}}{{{Barrett}, {Mandel}, {Neijssel}, {Stevenson} \& {Vigna-G{\'o}mez}}}}
\bibcite{2018MNRAS.477.4685B}{{8}{2018}{{{Barrett} et~al.}}{{{Barrett}, {Gaebel}, {Neijssel}, {Vigna-G{\'o}mez}, {Stevenson}, {Berry}, {Farr} \& {Mandel}}}}
\bibcite{belczynski2002comprehensive}{{9}{2002}{{{Belczynski} et~al.}}{{{Belczynski}, {Kalogera} \& {Bulik}}}}
\bibcite{2016Natur.534..512B}{{10}{2016}{{{Belczynski} et~al.}}{{{Belczynski}, {Holz}, {Bulik} \& {O'Shaughnessy}}}}
\bibcite{cappe2004population}{{11}{2004}{{{Capp{\'e}} et~al.}}{{{Capp{\'e}}, Guillin, Marin \& Robert}}}
\bibcite{2007arXiv0710.4242C}{{12}{2008}{{{Capp{\'e}} et~al.}}{{{Capp{\'e}}, {Douc}, {Guillin}, {Marin} \& {Robert}}}}
\bibcite{cornuet2012adaptive}{{13}{2012}{{Cornuet et~al.}}{{Cornuet, Marin, Mira \& Robert}}}
\bibcite{2016MNRAS.460.3545D}{{14}{2016}{{{}{de Mink} \& {Mandel}}}{{{}{de Mink} \& {Mandel}}}}
\bibcite{2018MNRAS.479..601D}{{15}{2018}{{{Del Pozzo} et~al.}}{{{Del Pozzo}, {Berry}, {Ghosh}, {Haines}, {Singer} \& {Vecchio}}}}
\bibcite{Dominik:2012kk}{{16}{2012}{{Dominik et~al.}}{{Dominik, Belczynski, Fryer, Holz, Berti, Bulik, Mandel \& O'Shaughnessy}}}
\bibcite{eglajs1977new}{{17}{1977}{{Eglajs \& Audze}}{{Eglajs \& Audze}}}
\bibcite{euler1782recherches}{{18}{1782}{{Euler}}{{Euler}}}
\bibcite{osti_4423221}{{19}{1948}{{Fermi \& Richtmyer}}{{Fermi \& Richtmyer}}}
\bibcite{2017ApJ...851L..25F}{{20}{2017}{{{Fishbach} \& {Holz}}}{{{Fishbach} \& {Holz}}}}
\bibcite{2018arXiv180700011F}{{21}{2018}{{{Foucart} et~al.}}{{{Foucart}, {Hinderer} \& {Nissanke}}}}
\bibcite{2012ApJ...749...91F}{{22}{2012}{{{Fryer} et~al.}}{{{Fryer}, {Belczynski}, {Wiktorowicz}, {Dominik}, {Kalogera} \& {Holz}}}}
\bibcite{1994A&A...282..801G}{{23}{1994}{{{Goldberg} \& {Mazeh}}}{{{Goldberg} \& {Mazeh}}}}
\bibcite{2014arXiv1411.3954H}{{24}{2014}{{{He} \& {Owen}}}{{{He} \& {Owen}}}}
\bibcite{doi:10.1080/00401706.1995.10484303}{{25}{1995}{{Hesterberg}}{{Hesterberg}}}
\bibcite{2007CSE.....9...90H}{{26}{2007}{{{Hunter}}}{{{Hunter}}}}
\bibcite{2000MNRAS.315..543H}{{27}{2000}{{{Hurley} et~al.}}{{{Hurley}, {Pols} \& {Tout}}}}
\bibcite{2002MNRAS.329..897H}{{28}{2002}{{{Hurley} et~al.}}{{{Hurley}, {Tout} \& {Pols}}}}
\bibcite{iman1980latin}{{29}{1980}{{Iman et~al.}}{{Iman, Davenport \& Zeigler}}}
\bibcite{iman1981approach}{{30}{1981}{{Iman et~al.}}{{Iman, Helton \& Campbell}}}
\bibcite{jones1977blindfold}{{31}{1977}{{Jones}}{{Jones}}}
\bibcite{kahn1951estimation}{{32}{1951}{{Kahn \& Harris}}{{Kahn \& Harris}}}
\bibcite{10.2307/166789}{{33}{1953}{{Kahn \& Marshall}}{{Kahn \& Marshall}}}
\bibcite{1996ApJ...471..352K}{{34}{1996}{{{Kalogera}}}{{{Kalogera}}}}
\bibcite{2000ApJ...541..319K}{{35}{2000}{{{Kalogera}}}{{{Kalogera}}}}
\bibcite{1998ApJ...493..351K}{{36}{1998}{{{Kalogera} \& {Webbink}}}{{{Kalogera} \& {Webbink}}}}
\bibcite{2018A&A...619A..77K}{{37}{2018}{{{Klencki} et~al.}}{{{Klencki}, {Moe}, {Gladysz}, {Chruslinska}, {Holz} \& {Belczynski}}}}
\bibcite{kluyver2016jupyter}{{38}{2016}{{Kluyver et~al.}}{{Kluyver et~al.,}}}
\bibcite{1993A&A...271..149K}{{39}{1993}{{{Kolb}}}{{{Kolb}}}}
\bibcite{2001MNRAS.322..231K}{{40}{2001}{{{Kroupa}}}{{{Kroupa}}}}
\bibcite{kruckow2018progenitors}{{41}{2018}{{{Kruckow} et~al.}}{{{Kruckow}, {Tauris}, {Langer}, {Kramer} \& {Izzard}}}}
\bibcite{liu2008monte}{{42}{2008}{{Liu}}{{Liu}}}
\bibcite{2018arXiv180605820M}{{43}{2018}{{{Mandel} \& {Farmer}}}{{{Mandel} \& {Farmer}}}}
\bibcite{10.1093/mnras/stw379}{{44}{2016}{{Mandel \& de~Mink}}{{Mandel \& de Mink}}}
\bibcite{2018arXiv180909130M}{{45}{2018}{{{Mapelli}}}{{{Mapelli}}}}
\bibcite{2016A&A...588A..50M}{{46}{2016}{{{Marchant} et~al.}}{{{Marchant}, {Langer}, {Podsiadlowski}, {Tauris} \& {Moriya}}}}
\bibcite{1992ApJ...401..265M}{{47}{1992}{{{Mazeh} et~al.}}{{{Mazeh}, {Goldberg}, {Duquennoy} \& {Mayor}}}}
\bibcite{10.2307/1268522}{{48}{1979}{{McKay et~al.}}{{McKay, Beckman \& Conover}}}
\bibcite{doi:10.1080/01621459.1949.10483310}{{49}{1949}{{Metropolis \& Ulam}}{{Metropolis \& Ulam}}}
\bibcite{2017ApJS..230...15M}{{50}{2017}{{{Moe} \& {Di Stefano}}}{{{Moe} \& {Di Stefano}}}}
\bibcite{2019arXiv190608136N}{{51}{2019}{{{Neijssel} et~al.}}{{{Neijssel} et~al.,}}}
\bibcite{1924PTarO..25f...1O}{{52}{1924}{{{{\"O}pik}}}{{{{\"O}pik}}}}
\bibcite{ortiz2000adaptive}{{53}{2013}{{{Ortiz} \& {Pack Kaelbling}}}{{{Ortiz} \& {Pack Kaelbling}}}}
\bibcite{doi:10.1080/01621459.2000.10473909}{{54}{2000}{{Owen \& Zhou}}{{Owen \& Zhou}}}
\bibcite{pennanen2006adaptive}{{55}{2006}{{Pennanen \& Koivu}}{{Pennanen \& Koivu}}}
\bibcite{2007CSE.....9c..21P}{{56}{2007}{{{Perez} \& {Granger}}}{{{Perez} \& {Granger}}}}
\bibcite{1996ApJ...465..338P}{{57}{1996}{{{Politano}}}{{{Politano}}}}
\bibcite{1998IAUS..191P.607P}{{58}{1998}{{{Pols} et~al.}}{{{Pols}, {Hurley} \& {Tout}}}}
\bibcite{robert2013monte}{{59}{2013}{{Robert \& Casella}}{{Robert \& Casella}}}
\bibcite{2019ApJ...872..105S}{{60}{2019}{{{Safarzadeh} et~al.}}{{{Safarzadeh}, {Ramirez-Ruiz}, {Andrews}, {Macias}, {Fragos} \& {Scannapieco}}}}
\bibcite{2012Sci...337..444S}{{61}{2012}{{{Sana} et~al.}}{{{Sana} et~al.,}}}
\bibcite{SmarrBlandford1976}{{62}{1976}{{Smarr \& D.~Blandford}}{{Smarr \& D.~Blandford}}}
\bibcite{2015MNRAS.451.4086S}{{63}{2015}{{{Spera} et~al.}}{{{Spera}, {Mapelli} \& {Bressan}}}}
\bibcite{stevenson2017formation}{{64}{2017}{{{Stevenson} et~al.}}{{{Stevenson}, {Vigna-G{\'o}mez}, {Mandel}, {Barrett}, {Neijssel}, {Perkins} \& {de Mink}}}}
\bibcite{2019arXiv190402821S}{{65}{2019}{{{Stevenson} et~al.}}{{{Stevenson}, {Sampson}, {Powell}, {Vigna-G{\'o}mez}, {Neijssel}, {Sz{\'e}csi} \& {Mandel}}}}
\bibcite{2018arXiv180608365T}{{66}{2018}{{{Taylor} \& {Gerosa}}}{{{Taylor} \& {Gerosa}}}}
\bibcite{2018arXiv181112907T}{{67}{2018}{{{The LIGO Scientific Collaboration} et~al.}}{{{The LIGO Scientific Collaboration} et~al.,}}}
\bibcite{torrie1977nonphysical}{{68}{1977}{{Torrie \& Valleau}}{{Torrie \& Valleau}}}
\bibcite{1991MNRAS.250..701T}{{69}{1991}{{{Tout}}}{{{Tout}}}}
\bibcite{2011CSE....13b..22V}{{70}{2011}{{{}{van der Walt} et~al.}}{{{}{van der Walt}, {Colbert} \& {Varoquaux}}}}
\bibcite{Veach:1995:OCS:218380.218498}{{71}{1995}{{Veach \& Guibas}}{{Veach \& Guibas}}}
\bibcite{2018MNRAS.481.4009V}{{72}{2018}{{{Vigna-G{\'o}mez} et~al.}}{{{Vigna-G{\'o}mez} et~al.,}}}
\bibcite{Woosley_2017}{{73}{2017}{{Woosley}}{{Woosley}}}
\bibcite{2019arXiv190210331Z}{{74}{2019}{{{Zackay} et~al.}}{{{Zackay}, {Venumadhav}, {Dai}, {Roulet} \& {Zaldarriaga}}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Derivation of the variance used for optimising the length of the \textsc  {STROOPWAFEL}{} exploration phase}{18}{section.A1}\protected@file@percent }
\newlabel{app:Fprior}{{A}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{section.A1}{}}
\newlabel{eq:CombinedDistributionApp}{{A1}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.1}{}}
\newlabel{eq:EstimateFexplApp}{{A2}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.2}{}}
\newlabel{integralB3}{{A5}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.5}{}}
\newlabel{integralB4}{{A6}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.6}{}}
\newlabel{z1weight}{{A8}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.8}{}}
\newlabel{z2weight}{{A9}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.9}{}}
\newlabel{integralB5}{{A10}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.10}{}}
\newlabel{eq:VarFpriorApp}{{A11}{18}{Derivation of the variance used for optimising the length of the \AISs {} exploration phase}{equation.A1.11}{}}
\citation{2018MNRAS.481.4009V}
\citation{stevenson2017formation,2018MNRAS.477.4685B,2018MNRAS.481.4009V}
\citation{2000MNRAS.315..543H}
\citation{1998IAUS..191P.607P}
\citation{SmarrBlandford1976}
\citation{2002MNRAS.329..897H,belczynski2002comprehensive,Dominik:2012kk}
\citation{2018MNRAS.481.4009V}
\citation{2001MNRAS.322..231K}
\citation{1991MNRAS.250..701T,1992ApJ...401..265M,1994A&A...282..801G,2012Sci...337..444S}
\citation{1924PTarO..25f...1O,1983ARA&A..21..343A}
\@writefile{toc}{\contentsline {section}{\numberline {B}Toy model}{19}{section.A2}\protected@file@percent }
\newlabel{app:toymodel}{{B}{19}{Toy model}{section.A2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Binary population synthesis model set-up}{19}{section.A3}\protected@file@percent }
\newlabel{app:COMPASdetails}{{C}{19}{Binary population synthesis model set-up}{section.A3}{}}
\citation{2018MNRAS.481.4009V}
\citation{2012ApJ...749...91F}
\citation{Woosley_2017}
\citation{2019arXiv190402821S}
\@writefile{lof}{\contentsline {figure}{\numberline {B1}{\ignorespaces Toy model illustration: distribution of the $10^6$ samples drawn in the the birth distribution Monte Carlo (left-panel) and \textsc  {STROOPWAFEL}{} (right panel) simulation. The panels show two-dimensional projections of $\qopname  \relax o{log}x_2$ and $x_3$ from the three dimensional parameter space. In both figures the sampling density (\leavevmode {\color {AISgray}gray}) is shown through a two-dimensional histogram with 100$\times $100 bins. Over plotted (\leavevmode {\color {AISgreen}green}) are the samples that lie within the volume $V_D$ and recover the rare outcome $D$. Dark regions surrounding the green areas of interest in the right plot indicate that our \textsc  {STROOPWAFEL}{} algorithm focuses more of the computational time around the region of interest.  }}{20}{figure.A2.1}\protected@file@percent }
\newlabel{fig:app-3dslicedResult}{{B1}{20}{Toy model illustration: distribution of the $10^6$ samples drawn in the the birth distribution Monte Carlo (left-panel) and \AISs {} (right panel) simulation. The panels show two-dimensional projections of $\log x_2$ and $x_3$ from the three dimensional parameter space. In both figures the sampling density (\textcolor {AISgray}{gray}) is shown through a two-dimensional histogram with 100$\times $100 bins. Over plotted (\textcolor {AISgreen}{green}) are the samples that lie within the volume $V_D$ and recover the rare outcome $D$. Dark regions surrounding the green areas of interest in the right plot indicate that our \AISs {} algorithm focuses more of the computational time around the region of interest}{figure.A2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B2}{\ignorespaces Toy model test result: $1 \sigma $ deviations from the true volume integral $V_D$ when estimating the fractional rate using \textsc  {STROOPWAFEL}{} with different values for the scaling factor of the width of the Gaussians $\kappa $ (left panel). The true fractional rate in the toy model is known and equals approximately $ 0.001$. The deviations are calculated by running 100 repeated simulations with a total number of $N = 10^6$ samples per simulation. The green contours show a $.3\%, 1\%$ and $3\%$ fractional sampling uncertainty on the rate estimate of the target population. On the right the $1 \sigma $ uncertainty of the traditional Monte Carlo sampled simulation is shown with an error bar; this matches the expected fractional uncertainty $1/\sqrt  {N_{\rm  {T}}}$. In this work we adopt $\kappa =2$ (red dotted line).}}{20}{figure.A2.2}\protected@file@percent }
\newlabel{fig:toymodelAbsError}{{B2}{20}{Toy model test result: $1 \sigma $ deviations from the true volume integral $V_D$ when estimating the fractional rate using \AISs {} with different values for the scaling factor of the width of the Gaussians $\kappa $ (left panel). The true fractional rate in the toy model is known and equals approximately $ 0.001$. The deviations are calculated by running 100 repeated simulations with a total number of $N = 10^6$ samples per simulation. The green contours show a $.3\%, 1\%$ and $3\%$ fractional sampling uncertainty on the rate estimate of the target population. On the right the $1 \sigma $ uncertainty of the traditional Monte Carlo sampled simulation is shown with an error bar; this matches the expected fractional uncertainty $1/\sqrt {N_{\rm {T}}}$. In this work we adopt $\kappa =2$ (red dotted line)}{figure.A2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Bandwidth variations of kernel density estimator}{20}{section.A4}\protected@file@percent }
\newlabel{app:KDEbandwidth}{{D}{20}{Bandwidth variations of kernel density estimator}{section.A4}{}}
\citation{2017ApJ...851L..25F}
\citation{2017ApJ...851L..25F}
\newlabel{lastpage}{{D}{21}{Bandwidth variations of kernel density estimator}{figure.A4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {D1}{\ignorespaces Predicted chirp mass distribution of the BH--BH merger population using \textsc  {STROOPWAFEL}{} (orange) and traditional (grey) sampling. In all cases the simulation uses $N= 10^6$ samples and the distributions are weighted to the sensitivity of gravitational-wave interferometers using \citet  {2017ApJ...851L..25F}. Shaded regions show the $1$- and $2$--$\sigma $ confidence intervals which are calculated by bootstrapping the samples 100 times. This distribution is for a particular set of model assumptions, including a single metallicity $Z = 0.001$, and an integration over a metallicity-dependent cosmic star formation history is required for comparisons with observations. The same \texttt  {scipy} kernel density estimator smoothing with a kernel density estimator factor for the bandwidth of about $0.044 $ (top panel) and $0.12 $ (middle panel) is used for the traditional and \textsc  {STROOPWAFEL}{} simulations. In the bottom panel a kernel bandwidth of about $0.044 $ is used for the \textsc  {STROOPWAFEL}{} method whereas for the traditional method we use a bandwidth of about $0.12$. }}{21}{figure.A4.1}\protected@file@percent }
\newlabel{fig:MchirpBandwidths}{{D1}{21}{Predicted chirp mass distribution of the BH--BH merger population using \AISs {} (orange) and traditional (grey) sampling. In all cases the simulation uses $N= 10^6$ samples and the distributions are weighted to the sensitivity of gravitational-wave interferometers using \citet {2017ApJ...851L..25F}. Shaded regions show the $1$- and $2$--$\sigma $ confidence intervals which are calculated by bootstrapping the samples 100 times. This distribution is for a particular set of model assumptions, including a single metallicity $Z = 0.001$, and an integration over a metallicity-dependent cosmic star formation history is required for comparisons with observations. The same \texttt {scipy} kernel density estimator smoothing with a kernel density estimator factor for the bandwidth of about $0.044 $ (top panel) and $0.12 $ (middle panel) is used for the traditional and \AISs {} simulations. In the bottom panel a kernel bandwidth of about $0.044 $ is used for the \AISs {} method whereas for the traditional method we use a bandwidth of about $0.12$}{figure.A4.1}{}}
